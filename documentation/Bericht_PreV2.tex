\documentclass{article}
\usepackage{graphicx}
\usepackage{forest}
\usepackage{tikz}
\usepackage{subcaption}
\usetikzlibrary{fit}
\graphicspath{ {./images/} }
\begin{document}
\title{An Implementation of Hypersuccinct Trees}
\author{Christopher Pack, Alexander Auras, Nathanael Stöhr, Charbono Lonyem Tegomo}
\date{\today}
\maketitle

%Write more in abstract
\begin{abstract}
This document describes an implementation of Hypersuccinct Tree encodings in C++, following the procedure described in \cite{farzanMunro} and \cite{universalSuccinct}.

\end{abstract}

\tableofcontents

\section{Introduction}
%Write more
Search for good (space and time efficient) encodings.\\
A proof of concept of an implementation.\\
Library meant to be open (extendable) and easy to use.

\section{The tree covering Algorithm}
To achieve the succinct encoding of the tree we follow the algorithm described by Farzan-Munro \cite{farzanMunro}. This algorithm has several steps. At first, the decompose-algorithm is used to divide the tree into several smaller subtrees of roughly equal size. These are called mini-trees. These mini-trees follow certain rules. Their nodes are disjoint, except they may have a common root node. Edges between mini-trees that do not share a common root node always end in the root node of the child tree and start from the root node of the parent tree, except for at most one edge in a mini-tree, that may start from any node in that tree and connect to the root of the child tree. We call this last special type of connection “dummy-interconnection”.\\
This allows to represent the interconnections of these subtrees with so called Fully Index-able Dictionaries (FIDs). Only the dummy-interconnections need their own handling. For these, we create a new dummy node on the interconnecting edge and store its pointer explicitly. Since there can at most be one such interconnection for each tree, the amount of created dummy nodes is bound by $O(log (n))$.\\
For the other types of interconnection, we distinguish between two types. Trees with type 1 interconnections share a common root node, while trees with type 2 interconnections are connected via an edge between their root nodes. With the FIDs and an additional vector we can represent both these interconnections. We create a FID for each root node. In the FID we store information about the child nodes of the root. This information allows us to identify which child nodes belong to a common tree. We use the additional vector, the Typevector (TV), to distinguish between interconnections of type 1 and type 2, by storing that information in 1 bit for each tree.\\
For each Mini-tree we store it's index in the FIDs and the data about its's Micro-trees together with some auxiliary information which will be described later. The size of this data of all Mini-trees is in $o(n)$ bits.

\subsection{Functions and Queries of the Hypersuccinct Tree}
To have a succinct data structure we have to be able to execute efficient query operations on our data. The auxiliary information stored for each Mini-tree is fundamental for that. In fact, the information we store allows us to execute many commonly needed query operations within $O(1)$ time. That means a lot of complex calculations are done upon creating the data and the results are then stored efficiently to be quickly available when asked for. \\

\begin{figure}
\begin{tabular}{ |p{3.5cm}p{8cm}|} 
 \hline
 child($v$, $i$) & The $i$-th child of node $v$. \\
 childRank($v$) & The index of node $v$ as child of it's parent node. \\
 getParent($v$) & The parent node of node $v$. \\
 degree($v$) & The degree (number of children) of node $v$. \\
 subtreeSize($v$) & The size of the tree with node $v$ as root. \\
 depth($v$) &  The number of edges from the root to the node $v$. \\
 height($v$) & The number of edges from the node $v$ to the furthest leaf in it's subtree. \\
 leftmostLeaf($v$) & The leftmost leaf descendant of node $v$. \\
 rightmostLeaf($v$) & The rightmost leaf descendant of node $v$. \\
 leafSize($v$) & The number of leaf nodes in the subtree of node $v$. \\
 leafRank($v$) & The number of leaves before and including $v$. \\
 \hline
\end{tabular}
\caption{Queries of the Hypersuccinct Tree}
\label{2.1:table1}
\end{figure}

\section{Our Implementation}
This section is a short description of our implementation, which is made in C++.
%Do we need something here?

\subsection{Goals of the Implementation}
This library is mainly ment to provide some practical proof that the encoding offered by \cite{farzanMunro} and \cite{universalSuccinct} works in practice. Be mindful that our goal was to implement a succinctly encoded tree as described in \cite{farzanMunro}, with huffman encoding being the only part from \cite{universalSuccinct} impacting our project, therefore other changes described in \cite{universalSuccinct} are not part of this implementation.\\
This still results in a library that is ready for use in actual programs, so long as the limited implementation of functions actually suffices, and we discuss some of the shortcomings of this implementation in \textit{section 5}. This library is meant to be open and further refining and adding functionality should be possible and would be appreciated.\\
The library offers basic functionality around the hypersuccinct tree encoding such as generating a hypersuccinct tree from an .xml file, saving an encoded tree to a file and reading encoded files. The hypersuccinct tree offers a variety of queries, all implemented with a time complexity of $O(1)$.

\subsection{External Libraries}
We use four external libraries in our project.
%Need Link to IrrXML
The first one, called Irrxml, serves an implementation to read efficiently from an xml file. We use this library to generate a basic tree structure from xml files which is then used for our encoding.\\
We make use of a small library which provides an implementation of space efficient Fully Indexable Dictionaries \cite{universalSuccinct}, called succinct\_bv, which is implemented as described in \cite{succinctBV}.
This library is very lightweight and has been modified personally by us to suit our needs.\\
%Need link for succinct_bv, Threading, and googletest
To increase the performance of our encoding process (see \textit{section 4.2}), we utilize a multithreading library. This library is called thread-pool, and was created by \cite{threading}, to provide an efficient multithreading library.\\
Lastly, we utilise the googletest library for unit tests.

\section{Implementation in Depth}
We present our implementation in detail, and highlight issues we encountered during our implementation process and how we solved them.
\subsection{The Hypersucccinct Tree class}
The Hypersuccinct Tree class implements the entire hypersuccinct tree encoding. It consists of a struct representing minitrees and one representing the lookup table entries.
Both of these structs use plenty of bitvectors to store relevant data for queries.\\

Hypersuccinct Nodes:\\
Nodes within the Hypersuccinct Tree are identified as triplets, where the first value denotes the Minitree, the second the Microtree and the third the Node number within the Microtree.\\

\subsubsection{The FID and identifying trees}
FIDs represent the interconnections between trees at their roots, their type 1 and type 2 connections \cite{farzanMunro}, together with a Type Vector that shows which kind of connection the tree has.
Due to the way they are being generated, the FIDs do not share indices with their respective trees (i.e. it is possible for the Minitree with $id = 7$ to be in the FID with $id = 5$).
This necessitates an index conversion whenever the FID or the type vector is used. Doing this conversion at runtime would not be possible within $O(1)$, since it would be necessary to go through each FID and count the trees contained within it, for both type 0 and type 1 connections.
This is further complicated by taking into account the fact that each tree without dummies is actually accounted in two different FIDs. Firstly in the FID of its own root as a type 0 connection (Top FID), and secondly in the FID of its parent as type 1 (Low FID). Trees below dummies however have no low FID, as they are not directly below the root of their parent tree.
\begin{figure}[h]
	\begin{tabular}{ |p{3.5cm}||p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|  }
		 \hline
		 \multicolumn{9}{|c|}{Vector indices for Trees} \\
		 \hline
		 Minitree Number & 0 & 1& 2 & 3 & 4 & 5 & 6 & 7\\
		 Minitree Top FID& 0 & 1 & 2 & 3 & 4 & 5 & 6 & 6\\
		 Minitree Low FID& - & 0 & 0 & 2 & 2 & 3 & - & -\\
		 \hline
	\end{tabular}
\caption{Indices for Minitrees}
\label{fid:table1}
\end{figure}
Therefore we implement a two way index conversion by directly pointing to the type 0 and type 1 FID index for each tree, and pointing to the first type 0 and type 1 tree for each FID. Since this is $O(4 \times |Minitrees|) + O(4 \times |Microtrees|)$, it is still within our required space complexity. Dummies on the other hand use direct pointers to their children.\\
\begin{figure}[h]
	\begin{tabular}{ |p{3.5cm}||p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|  }
		 \hline
		 Bitvector & Bit 1 &Bit 2&Bit 3&Bit 4& Bit 5 &Bit 6&Bit 7&Bit 8\\
		 \hline
		 Minitree FID 0 & 1 & 1& 0 & 1 & 0 & 0 & 1 & 1\\
		 Minitree Typevector 0& 0 & 1 & - & 0 & - & - & 1 & 0\\
		 Minitree Numbers & 0 & 3 &  0 & 1 & 1 & 1 & 5 & 2\\
		 \hline
		 Minitree FID 1 & 1 & 0& 1 & 1 & 0 & 1 & 1 & 1\\
		 Minitree Typevector 1& 0 & - & 1 & 1 & - & 1 & 1 & 0\\
		 Minitree Numbers & 3 & 3 &  6 & 7 & 3 & 8 & 9 & 4\\
		 \hline
	\end{tabular}
\caption{FID, Typevector and corresponding trees}
\label{fid:table2}
\end{figure}
The second issue arises when trying to analyze the FID and Typevectors of the Hypersuccinct Tree. Identifying which tree is at which position within even a single FID is not trivial. As demonstrated in \textit{Figure 2}, the second low tree in the first FID is $5$, because the FID of tree $3$ contains tree $4$ already as a top tree, meaning correctly identifying Bit $7$ as tree number $5$ requires analysis of the FID of tree number $3$. Additionally, it is important to note that the FID with the ID of $1$ starts with the tree numbered $3$, which can only be known if all previous FIDs are also analyzed. Both of these computations exceed our time requirement of $O(1)$. Finding the first trees of any FID is clearly recursive starting from FID $0$, while correctly identfying low trees requires checking $|Low Trees|$ many additional FIDs. Therefore, the first top and low tree of any FID is pointed to directly.
This solves both of our issues, as the Rank of the Typevector indicates which FID belongs to which respective lower tree, allowing us to just take their first top tree as a result in $O(1)$. Knowing which tree an FID starts with is trivial with such pointers.


\subsubsection{The Hypersuccinct Tree Factory}
The Hypersuccinct Tree Factory is tasked with generating a hypersuccinct tree from our generic \textit{Unordered Tree} object, which is generated when reading an xml file. Additionally, the Factory also supports generating a tree directly from a full succinct Bitvector to support reading encoded files.\\
Encoding a generic tree is rather complicated due to the large amount of query related bitvectors that need to be filled with their respective data, a task that is not easily done on the generic tree structure. The complexity is therefore at least $O(|Nodes|^3)$, as we need to iterate through each minitree, within we iterate through each microtree, within we iterate through each node, as generated with the Farzan-Munro Algorithm by \cite{farzanMunro}. To increase the performance of this function, we make use of the multithreading library by \cite{threading}.\\
In contrast recreating a hypersuccinct tree from an encoded file is straightforward and easy. The data values from the file are just copied directly into their expected bitvector fields, which requires a complexity of $O(|Minitrees|) + O(|Lookup table entries|)$. Note that the file encoding is extremely space efficient and does not provide any ways to check if a given file is correctly encoded.\\
The Hypersuccinct Tree Factory generates all data necessary for query execution in $O(1)$, therefore fills all vector fields in Hypersuccinct Tree. The function is structured in loops and works as described in \cite{farzanMunro}. First, the Farzan Munro algorithm is executed on a base tree with the computed Minitree size of $\lceil log^2( |Nodes| ) \rceil$. Right after this, the Minitree interconnections are handled and Minidummies are generated. Then, the Farzan Munro algorithm is used on all generated Minitrees to generate their respective Microtrees of size $\lceil log( \frac{|Nodes|}{8} ) \rceil$, and their interconnections are handled. At last, for each of these Microtrees, a Lookup table entry is generated if an entry of such a tree sturcture does not already exist.\\
There are some special cases that lead to some additional complexity.

\begin{figure}[ht]
	\begin{subfigure}{3cm}
		\includegraphics[scale=0.2]{F3C1Tree}
		\caption{Node order without Dummies}
		\label{factory:subim1}
	\end{subfigure}
	\begin{subfigure}{3cm}
		\includegraphics[scale=0.2]{F3C2Tree}
		\caption{Node order with Dummies}
		\label{factory:subim2}
	\end{subfigure}
	\begin{subfigure}{2.5cm}
		\includegraphics[scale=0.2]{F3C4Tree}
		\caption{Minitree specific node numbers}
		\label{factory:subim4}
	\end{subfigure}
	\begin{subfigure}{2.5cm}
		\includegraphics[scale=0.21]{F3C3Tree}
		\caption{Final Node numbers}
		\label{factory:subim3}
	\end{subfigure}

\caption{Special Cases regarding node order}
\label{factory:images4}
\end{figure}

The first issue originates from the handling of interconnections and the node numbering. Adding dummies in the Unordered Tree class does not retain the original structure of the nodes, especially when the Minidummy is located right after the Microdummy on the same level (\textit{Case a and b}). Therefore it becomes necessary to generate a consistent node numbering, which requires sorting the nodes within each tree. For this an \textit{enumerate} function is implemented that creates a consistent order for nodes within Mini and Microtrees.\\
Another issue is the identification of Minitree dummies within Microtrees. Minitree dummies are originally identified by their node number respective to the Minitree. However, due to the structure of Hypersuccinct nodes, it is necessary to translate the Minitree node numbers to Microtrees and Microtree node numbers. To solve this, we implemement a Microtree and node pointer for each Minitree dummy.

\subsection{Query structures and differences}
Not all queries represented in \cite{farzanMunro} are implemented. This is in part due to the simplicity of this implementation, but also because the original paper is rather shortworded when describing the implementation of each query, or simply points towards other papers related to this topic, which were not part of the scope of this implementation.
Due to this there are some minor or notable differences to the paper at hand, which will be elaborated on in this section.

\subsubsection{Simple Queries}
As simple Queries we identify those queries that only require a single bitvector per level of abstraction. This means that these queries need one bitvector for values of each Minitree, one for each Microtree within the Minitrees and one for each lookuptable entry.
As a result these queries all follow a similar structure, first handling single nodes, then generalizing the result to Microtrees and at last taking Minitrees into account to arrive at the correct result with an $O(1)$ time complexity.\\
These queries are:\\
\begin{itemize}
	\item[1)] \textit{getParent}
	\item[2)] \textit{degree}
	\item[3)] \textit{subtreeSize}
	\item[4)] \textit{depth}
	\item[5)] \textit{height}
	\item[6)] \textit{leftmostLeaf}
	\item[7)] \textit{rightmostLeaf}
	\item[8)] \textit{leafSize}
	\item[9)] \textit{levelSuccessor (Not implemented)}
	\item[10)] \textit{levelPredecessor (Not implemented)}
\end{itemize}
These queries are described as using one bitvector per abstraction in the paper. We therefore believe this implementation to be as described in the paper.\\
\textit{Depth} is specifically easy, since the depth of a given MicroTree or MiniTree root is just the size of their FIDs, making extra data bitvectors for depth unnecessary on a Minitree and Microtree level. All other queries use their respective bitvectors to determine a result.\\
\textit{getParent} is not directly mentioned as a query in \cite{farzanMunro}. Instead, when describing the \textit{childRank} query, it is mentioned that we first have to identify the parent of the given node. We decided to make this into a separate helper query, anticipating to need this query for some other queries as well. As we already had the helper query, we also made a normal query out of it.
On Dummies:\\
These queries require to handle the dummy in query-specific ways. \textit{Depth} is the simplest query, only adding values from Minitree depth, Microtree depth and Node depth. These do already ignore dummies in their data, so this query does not require any dummy handling. \textit{Height} and \textit{subtreeSize} make use of the \textit{isDummyAncestor} helper queries to subtract the dummy from their calculations. \textit{Degree}, \textit{leftmostLeaf} and \textit{rightmostLeaf} check whether or not the current node is the dummy, and then move along its pointer. \textit{GetParent} simply checks if the result is a dummy, and then returns the parent of that dummy. This is still within $O(1)$, as there are at most two dummies (one Microdummy and one Minidummy) on top of one another.\\
Despite not being implemented, we can still make some observations about 
\textit{levelSuccessor} and \textit{levelPredecessor}. Both cannot use the FID to compute their results, as identifying a specific node in the FID is not possible in $O(1)$. We therefore believe that a bitvector pointing to either the FIDs position or directly to the successor/predecessor is necessary, therefore making both of these Simple Queries. For dummies both would use the same handling as getParent, as the value returned by the dummy is the correct one, whereas the dummy's child would be effectively one level too low.

\subsubsection{Rank Queries}
Rank Queries are all queries that return some sort of rank from the tree. These queries are more compicated than Simple Queries since they require more than one bitvector per abstraction.
Rank queries specifically need two bitvectors for the Minitree and Microtree abstractions, due to special cases.
They also require use of the FID to identify these special cases.\\
The Rank Queries are:\\
\begin{itemize}
	\item[1)] \textit{childRank}
	\item[2)] \textit{leafRank}
	\item[3)] \textit{nodeRank (Not implemented)}
\end{itemize}
The first issue comes up regarding the identification of the given node within an FID. As the FID is structured it is not trivial to identify FID and the position of a node within the FID and would require $O(|TreesInFID|)$ time. To avoid this, our implementation uses the FID to identify the special cases and then take information from additional bitvectors.

\begin{figure}[ht]
	\begin{subfigure}{2cm}
		\includegraphics[scale=0.22]{F4C1Tree}
		\caption{Case 1}
		\label{rank:subim1}
	\end{subfigure}
	\begin{subfigure}{2cm}
		\includegraphics[scale=0.21]{F4C2Tree}
		\caption{Case 2}
		\label{rank:subim2}
	\end{subfigure}
	\begin{subfigure}{3cm}
		\includegraphics[scale=0.2]{F4C3Tree}
		\caption{Case 3}
		\label{rank:subim3}
	\end{subfigure}
	\begin{subfigure}{3cm}
		\includegraphics[scale=0.2]{F4C4Tree}
		\caption{Case 4}
		\label{rank:subim4}
	\end{subfigure}

\caption{4 Special Cases for Rank Queries}
\label{rank:images4}
\end{figure}

\begin{figure}[ht]
	\begin{tabular}{ |p{4cm}||p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|  }
		 \hline
		 \multicolumn{5}{|c|}{Bitvectors} \\
		 \hline
		 Bitvector & Case 1 &Case 2&Case 3&Case 4\\
		 \hline
		 Minitree FID   & 1    & 1&   11 & 110\\
		 Minitree Typevector&   0  & 0   & 10 & 010\\
		 Microtree FID&11 &11&  irrelevant&irrelevant\\
		 Microtree Typevector&10& 10&  irrelevant&irrelevant\\
		 \hline
	\end{tabular}
\caption{FID and Typevector values for special cases}
\label{rank:table4}
\end{figure}

\textit{Case 1} and \textit{Case 2} describe a situation in which a higher indexed Microtree has a lower rank than the current Microtree. To resolve this, we introduce an extended rank bitvector which notes the rank of the first child of our current Microtree within the Minitree. This resolves this case on a data level, the second issue is to actually read the value of the extended bitvector in the right cases. This is where we differentiate between the two cases. If this problem appears at the Minitree root, we can identify this case by using the FID, resulting in \textit{Case 1}. If this problem appears further down in the Minitree we can compare values of Microtree and Node indices to identify \textit{Case 2}. \textit{Case 3} describes a similar issue regarding the Minitree. Again, a Minitree with a higher index has a lower rank than our current Minitree due to being a type 1 tree in the FID. This can also be identified with the FID. The three cases are mutually exclusive since they describe a similar issue.
\textit{Case 4} describes a tree of type 0 that is split by a tree of type 1 in between. This can be identified, since 0s in the FID must belong to the last type 0 tree, meaning after identifying the latest tree as being of type 1, one only needs to check if the index points to a 0 in the FID.\\
The structure of both queries is similar. First they calculate the result of only the node within the Microtree, using the values from the lookup table. Then, the result is generalized to a Microtree. Here, \textit{Case 2} is evaluated. At last, the result is generalized to the Minitree by analyzing key structures of the FID to identify \textit{Case 1}, or \textit{Case 3}. In \textit{childRank}, the special cases immediately return the value, as this query only needs to take into account the singular values of the parent FID. For \textit{leafRank}, a generalization to the entire tree is always necessary due to the result being sensitive to the entire tree topology.\\
Both implemented queries use \textit{getParentForQuery} as a helper query to identify the direct parent of the current node. These queries only check if the current node is a child of a dummy and if that is the case, the dummy is used instead, as the dummy is at the correct position to calculate the correct result.\\
These special cases are not mentioned in \cite{farzanMunro}. The description of all Rank Queries are rather short and fairly inconclusive.\\ 
It is for example correct that we use the FID to compute the childRank. However, we interpret the paper to say that computing the childRank is possible by just using the FID, without any additional data. 
Since this is not possible due to the identification of a node within the FID requiring $O(|Trees In FID|)$ time, our implementation uses the FID to identify the special cases. Both implemented Rank Queries also need to take their direct ancestor into account, which is not mentioned for LeafRank.
We believe our approach to be adequate, since both implemented queries fulfill the $O(1)$ time requirement without violating the space requirement. Additionally, both of our Rank Queries are very similar in their implementation offering easier understandability and openness, since adding \textit{nodeRank} would most likely just require the exact same steps as taken in our approach to Rank Queries.

\subsubsection{Child}
\textit{Child} is a more unique query. \textit{Child} is simpler than rank queries in principle, since the index provided by the query is directly related to an FID position, allowing an analysis of the node at that position in $O(1)$. It is important to note that identifying the correct child within the FID can point to a 0 value in the FID, and all issues for identifying nodes in the FID (\textit{Section 4.1.1}) apply here, making this query more complex.
This means that we need to identify Microtrees and nodes via the distance from the last $1$ within the respective FID of the Mini and Microtrees. To implement this, we first just identify the correct Minitree and reduce the remaining index by the position of that Minitree in the FID.
The process for identifying the Microtree is analogous to that, and at last we use the remaining index to select a specific node via the lookup table. If our starting node is already below the Minitree root, the part for identifying the right Minitree is skipped, same for Microtrees if we are below a Microtree root.
Dummy-nodes are skipped, both if the starting node is a dummy, in which case child of the direct pointer of the dummy is used instead, or if the result node is a dummy, in which case the direct pointer of the dummy is returned instead.\\
One thing we want to highlight is the identification of single nodes, below the Microtree. As \cite{farzanMunro} already describes, an Ancestor matrix is utilized for lookuptable entries (\textit{Section 4.2.4}). Therefore, we first implemented a child matrix alongside it, to identify children within Microtrees. We were however not able to identify a way to implement this task in $O(1)$ without making use of \textit{Rank} and \textit{Select} queries, requiring us to implement a FID for the matrix, increasing the space complexity.

\subsubsection{Helper Queries}
Instead of being identified by their algorithmic structure, these queries are identified by the fact that they are used by other queries to compute their results.\\
These Helper Queries are:
\begin{itemize}
	\item[1)] \textit{isDummyAncestorWithinMiniTree}
	\item[2)] \textit{isDummyAncestorWithinMicroTree}
	\item[3)] \textit{getParentForQuery}
\end{itemize}
Their implementation is similar to the implementation of Simple Queries.\\
\textit{GetParentForQuery} is a special version of \textit{getParent} that excludes handling for dummy nodes. This is necessary to identify special dummy cases in the queries that use this Helper Query (such as \textit{child}).
The \textit{isDummyAncestor} helper queries identify if a given node is an ancestor of a Minidummy or a Microdummy respectively. \textit{IsDummyAncestorWithinMiniTree} has a similar structure to the simple queries, first using specific bitvector data that contains if the Microtree root is an ancestor of the dummy, then if the specific node is the ancestor. \textit{IsDummyAncestorWithinMicroTree} is even simpler, only needing to determine the answer for specific nodes. Both queries are necessary to evaluate an entire tree structure in $O(1)$, since they prevent the necessity to analyze every node on the structure individually, which would be $> O(1)$. These queries utilize the lookuptable's ancestor matrix as described by \cite{farzanMunro}.

\subsubsection{Other Queries / Not implemented queries}
The following queries are not implemented and are not similar enough to already implemented queries to use those as a template. We briefly describe our issues with those queries.
\begin{itemize}
	\item[1)] \textit{nodeSelect (Not implemented)}
	\item[2)] \textit{levelAncestor (Not implemented)}
	\item[3)] \textit{lowestCommonAncestor (Not implemented)}
	\item[4)] \textit{distance (Not implemented)}
	\item[5)] \textit{levelLeftmostNode (Not implemented)}
	\item[6)] \textit{levelRightmostNode (Not implemented)}
\end{itemize}
Moving multiple levels is not trivial with our encoding. Since this is supposed to work in $O(1)$ time we are not sure how to implement a level based query. Moving up one level at a time is $> O(1)$, but adding one bitvector per level for each Microtree violates the space complexity requirement. This issue applies to queries \textit{2) to 6)}.\\
\textit{NodeSelect} has to call to a full mapping that orders all nodes with a single index, which is not how Hypersuccinct nodes are represented. Again, saving such a map for each Microtree and Minitree violates our space complexity requirement, but computing it violates the time complexity requirement.

\subsection{Other Classes}
There are a variety of other classes within the library that contribute to the functionality of our library.
\begin{itemize}
	\item[1)] \textit{Bitvector Utils}\\
			Bitvector Utils is a basic class that provides utility functions for Bitvectors. Its main function is to typecast Bitvectors to Integers and back, which is possible in $O(1)$ due to the limited size of Integers. (i.e. \textit{uint32\_t} has a maximum of $32$ bits.)
	\item[2)] \textit{HST Output}\\
			The HyperSuccinctTree Output class provides functions for writing and reading a Hypersuccinct Tree class. Therefore this class handles writing Hypersuccinct Trees to Files or reading Hypersuccinct Trees from Files. It also supports writing the entire tree into the console.
	\item[3)] \textit{Unordered Tree}\\
			Unordered Tree is our basic tree implementation, to which an xml tree is parsed. Unordered Trees are then used to create Hypersuccinct Trees.
	\item[4)] \textit{Precomputed Function and Cached Function}\\
			These two classes are used to improve the performance of the \textit{HypersuccinctTreeFactory}'s \textit{create} function by either completely precomputing values for queries within the Unordered Tree, or by caching already calculated values.
	\item[5)] \textit{XML Reader}\\
			This class reads the actual xml file and creates an Unordered Tree from it.
	\item[6)] \textit{Farzan Munro}\\
			The Farzan Munro class implements the algorithm as presented in \cite{farzanMunro}. It therefore implements \textit{decomopose} and \textit{greedilyPack}. It also orders the created Tree afterwards to guarantee a consistent order within the hypersuccinct tree.
\end{itemize}

\section{Runtime tests}
In order to test if our code fulfills the aforementioned boundaries of time we implemented several tests. Each of these tests first encodes a xml-file to a Hypersuccinct Tree, then runs several queries on up to 1000 nodes of the tree and records the time it takes to run for each run query. With these records we can show how fast the calls to each query where executed and calculate averages or boxplots. This, however, does not take into account the speed of the machine or other randomness effects related to the execution of the code on our computers.\\

\section{Complexity Benchmarks}
In this section we discuss some specific design decisions and shortcomings, and how they affect the performance of our hypersuccinct encoding.
\subsection{Huffman encoding}
\begin{figure}[h]
	\begin{tabular}{ |p{3cm}||p{2cm}|p{2cm}|p{4cm}|  }
		 \hline
		 Tree Name & Normal &Huffman &Huffman + Lookuptable\\
		 \hline
		 TreeNath.xml   & 52    & 23 &   24 \\
		 TreeNath2.xml&   484  & 256   & 266 \\
		 TreeNath3.xml&5196 &2695&  2706\\
		 TreeNath4.xml&53369& 31709&  31732\\
		 TreeNath5.xml&583289&345005&345029\\
		 XMark2.xml&2004196&831572&831627\\
		 DBLP.xml&3690039&593804&593842\\
		 \hline
	\end{tabular}
\caption{Space for normal encoding and huffman encoding}
\label{huff:table1}
\end{figure}
Our tree offers two types of encoding for Microtrees. The first option encodes trees according to \cite{farzanMunro}, and uses the Microtree's balanced parenthesis representation, while the other utilizes a huffman encoding for the Microtrees. For that, the Microtrees use their respective huffman codes in the representation, while their corresponding lookup table entries contain the balanced parenthesis representation for each code.\\
The huffman encoding has no impact on query performance, as finding a corresponding lookup table entry for a huffman code is possible in $O(1)$. Encoding trees with huffman has a significant impact on the space necessary for the hypersuccinct tree. The balanced parenthesis representation needs $2n$ many bits for a tree of size $n$.\\
%Huffman theory bit
Huffman code ist optimal für diskrete gedächtnislose Quellen. Anzahl der Microtrees ist eine diskrete gedächtnislose Quelle. Einsparung schon allein ziemlich gut, da bp enconding 2n ist, und huffman code schon für nur 1n optimal wäre. %Need complexity?? of huffman code.

\subsection{Factory Complexity}
The encoding process in \textit{create} is obviously not possible in $O(1)$, due to the Farzan-Munro algorithm itself being more complex, and the current implementation amounts to roughly $O(n^{3})$. Despite that we put significant effort into increasing the performance of the encoding process. The \textit{create} was evaluated in four separate options, whether or not to use huffman encoding, and whether or not to generate query data.\\
We in addition to that we also analyzed the runtime of \textit{writeToFile} and \textit{readFromFile}.
\begin{figure}[h]
	\begin{tabular}{ |p{3cm}||p{2,5cm}|p{2,5cm}|p{2,5cm}| }
		 \hline
		 Tree Name & Create & Write File &Read File\\
		 \hline
		 TreeNath.xml   & 00:00:00.056    & 00:00:00.003 &   00:00:00.026 \\
		 TreeNath2.xml&   00:00:00.081  & 00:00:00.003   & 00:00:00.023 \\
		 TreeNath3.xml&00:00:00.209 &00:00:00.033&  00:00:00.073\\
		 TreeNath4.xml&00:00:02.266& 00:00:00.308&  00:00:00.510\\
		 TreeNath5.xml&00:00:36.357&00:00:03.558&00:00:06.413\\
		 XMark2.xml&00:00:58.005&00:00:07.645&00:00:20.307\\
		 DBLP.xml&00:04:52.509&00:00:10.888&00:00:30.038\\
		 \hline
	\end{tabular}
\caption{Average runtimes for create, writing and reading files for specific trees}
\label{complexFac:table1}
\end{figure}
%Insert New image
\begin{figure}[h]
\includegraphics[scale=0.3]{file_comp_cut}
\caption{Complexity of \textit{create}}
\label{complexFac:image1}
\end{figure}

\subsection{Query complexity tests}
For query runtime tests we used \textit{DBLP}, which is a large, flat tree, and \textit{treeNath1-5}, which are trees of growing size and depth. The records we got from these tests show that queries on Hypersuccint Trees of vastly different size are still in the same magnitude of execution time. The longer execution times of larger trees compared to smaller trees can be accounted longer access times related to caching and hardware behaviour. The code itself maintains it's $O(1)$ execute time magnitude.\\
\begin{figure}[h]
\includegraphics[scale=0.3]{treeNath3.xml}
\includegraphics[scale=0.3]{DBLP_Queries}
\caption{Complexity of implemented queries}
\label{complexQue:image1}
\end{figure}
%\includegraphics[width=\textwidth]{treeNath5.xml}\\
%I think there is no good way to unify the different images from different trees.
The queries provided by the hypersuccinct tree are implemented in $O(1)$, as specified in
\cite{farzanMunro}. As shown in \textit{Fig. 9} all queries except \textit{child} have an average runtime of well below $100 \mu s$. When it comes to \textit{child} when comparing between our different trees, the average runtime of \textit{child} increases with an increased amount of nodes. However, when analyzing our code, we were not able to find a section that would violate the $O(1)$ complexity requirement, not in our query implementation nor in the \textit{succinct\_bv} library. With some testing we determined that the increase in runtime stems from the basic function \textit{getMinitree}, which returns the Minitree for a given index, which is important for our evalutation, as hypersuccinct nodes save their Minitree as an integer (see Section 4.1).
%SPECULATION
Since this function simply calls the \textit{[]} operator of \textit{std::vector}, which per the C++ definition is $O(1)$. We argue that at some point a maximum runtime is reached and that this increase therefore does not violate our complexity requirement.

\subsection{Space complexity}
%Make Subsubsections
%More math
%Make Equations more beautiful (in the text)
%Also include what each query contributes to complexity
The hypersuccinct tree class saves first some simple data, such as a flag for huffman encoding, its size, and the calculated sizes of its Minitrees and Microtrees, as calculated according to \cite{farzanMunro}. These values all have a maximum length and therefore are $O(1)$. Next, we have a variety of Bitvectors regarding indices for FIDs and Minitrees which save values for each Minitree or each FID, therefore amounting to $O(|Minitrees|)$ and $O(|FIDs|)$. We save the data of the FID and its Typevector in $O(|FIDs|)$, while the Dummys of Minitrees are $\epsilon O(|Minitrees|)$. The FIDs and Typevectors also implement \textit{Rank} and \textit{Select} queries, which is $= |FIDs| \times (|FIDs| + O(\frac{|FIDs| log log |FIDs|}{log |FIDs|}))$, as described in \cite{succinctBV}.
\subsubsection{Minitree Complexity}
The Minitree vector obviously has $|Minitrees|$ many elements, as the Lookuptable has $|Lookuptable entries|$ many entries.\\
The Minitrees themselves save data for their Microtrees and the queries. All query data used for the Minitree itself is just a single value and therefore $O(1)$, while all data for Microtrees if $O(|Microtrees|)$. The FID, Typevector and Dummys for Microtrees have the same complexity as their counterparts for Minitrees, $O(|Micro FIDs|)$ and $O(|Microtrees|)$, and the implementation for \textit{Rank} and \textit{Select} are $= |MicroFIDs| \times (|MicroFIDs| + O(\frac{|MicroFIDs| log log |MicroFIDs|}{log |MicroFIDs|}))$. The bitvector that denotes the Microtrees themselves can be encoded in two ways, either using a balanced parentheses encoding that takes $|microtrees| \times |microsize| \times 2$ space, or a huffman encoding that takes $|microtrees| \times$ %??? Huffman???
both of which are $\epsilon O(|Microtrees|)$.
Therefore in total, the Minitrees have a complexity of $O(|Microtrees|)$.
\subsubsection{Lookuptable complexity}
For a lookuptable entry of a tree of size $m$, its complexity is:
\begin{itemize}
	\item[-] $O(2m)$ for \textit{index} and \textit{bp}
	\item[-] $O(m^{2})$ for both \textit{ancestorMatrix} and \textit{childMatrix}
	\item[-] $O(m^{2}) \times (m^{2} + O(\frac{m^{2} log log m^{2}}{log m^{2}}))$ for \textit{Rank} and \textit{Select} support for both matrices.
	\item[-] $O(m)$ for all other query data.
\end{itemize}
This amounts to the total complexity of Lookuptables to be $O(m^{2}) \times (m^{2} + O(\frac{m^{2} log log m^{2}}{log m^{2}}))$.
\subsubsection{Total space complexity}
Coming together for the entire tree, all Minitree data in the base tree is $\epsilon O(|Minitrees|)$ and the Minitrees are $ \leq |Minitrees| \times O(|Microtrees|)$. 
The amount of lookuptable entries is $\leq$ \textit{(number of unlabeled ordered trees with (} $microsize \times 2$ \textit{) nodes)}, OEIS000108, Catalan Numbers. Therefore the total complexity of the lookuptable is $\leq C(microsize \times 2) \times O((microsize \times 2)^{2}) \times ((microsize \times 2)^{2} + O(\frac{(microsize \times 2)^{2} log log (microsize \times 2)^{2}}{log (microsize \times 2)^{2}}))$.\\
Due to the calculation via the farzanMunro algorithm, it follows that:
$$size > |Minitrees|$$
$$size > |Microtrees|$$
$$size > m$$
Therefore:
$$|Minitrees| \times O(|Microtrees|) \leq O(n^{2})$$
$$C(microsize \times 2) \times O((microsize \times 2)^{2}) \times ((microsize \times 2)^{2} +$$ $$O(\frac{(microsize \times 2)^{2} log log (microsize \times 2)^{2}}{log (microsize \times 2)^{2}})) \leq C(size) \times O(size^{2}) \times (size^{2} + O(\frac{size^{2} log log (size^{2})}{log (size^{2})}))$$
%Just proving < n^2 or so will prob not suffice.



\subsubsection{Space Complexity concessions}
While the encoding is efficient in size when saving a tree to a file, within the program, the amount of space required to run trees is a lot larger. This technically does not break the space complexity, simply adding a large constant factor to it, but this is still notable. We identify the following reasons for this discrepancy:\\
\begin{itemize}
	\item[1)] The implementation of \textit{Bitvector} in $C++$ saves its data as \textit{uint32\_t}, which is always 32 bits long. This is a massive waste of space, since most values are much smaller than 32 bits.
	\item[2)] The \textit{succinct\_bv} library does not meet the perfect space complexity from \cite{succinctBV} of $log(\begin{array}{c} n \\ r \end{array}) + O(\frac{n log log n}{log n})$, and instead has a complexity of $n + O(\frac{n log log n}{log n})$.
\end{itemize}
For \textit{1)}, we believe it to be possible to save the entire hypersuccinct tree in a single bitvector. It should be possible to use pointers to access different parts of this bitvector in $O(1)$ using a variable cell array, as described in \cite{universalSuccinct}.\\
For \textit{2)}, it is obviously necessary to either use a library that offers the improved complexity, or to improve the current library.

\section{Conclusion?}

%Add Data
%We def. need references to the trees we used.
%But is this the right way?
\section{Data}
All trees can be found in the resources folder of our project on GitHub.
\subsection{Used xml tree files}
\begin{figure}[h]
	\begin{tabular}{ |p{3cm}||p{2,5cm}| }
		 \hline
		 Tree Name & Size\\
		 \hline
		 TreeNath.xml   &77 \\
		 TreeNath2.xml&  837 \\
		 TreeNath3.xml&9197\\
		 TreeNath4.xml&101157\\
		 TreeNath5.xml&1112717\\
		 XMark2.xml&3603803\\
		 DBLP.xml&7146530\\
		 \hline
	\end{tabular}
\caption{sizes of our xml trees}
\label{data:table1}
\end{figure}
%Make sure NOTHING is below bibliography

\bibliographystyle{plain}
\bibliography{references}

\end{document}
